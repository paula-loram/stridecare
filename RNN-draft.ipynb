{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4793220e-c870-44bb-b0c6-ab718277123b",
   "metadata": {},
   "source": [
    "- What is the input shape going to be?\n",
    "\n",
    "- Target categories we're going to have (6):\n",
    "    - Healthy (NoInjury)\n",
    "    - Knee\n",
    "    - Thigh\n",
    "    - Lower Leg (shin/calves)\n",
    "    - Ankle + Foot\n",
    "    - Hip/Pelvis + LumbarSpine + SI.Joint\n",
    "\n",
    "- We're using LSTM instead of GRU (? .. check)\n",
    "\n",
    "- How many hidden layers / dense layers?\n",
    "\n",
    "- Please Check: activation, loss, optimizer?\n",
    "- Fine-tune hyperparameters: epochs, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63dda415-9172-44a0-aff1-b1e0412ff647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0. Imports\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9926e817-aad1-455f-b841-cf4b30b74f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee2cc5bd-3175-4288-9711-aa30d1b96f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata_df = pd.read_csv(\"stridecare/data/meta/metadata_for_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e2f4ba6-924f-4958-8942-ebe7543f2b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_df['bq_name'] = metadata_df['filename'].apply(lambda x: 'angles_' + x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f375d5e0-d96d-40d0-9fc0-563d44753321",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on angles_20101005T132240\n",
      "(10, 12000)\n",
      "working on angles_20101117T132240\n",
      "(10, 12000)\n",
      "working on angles_20120703T102550\n",
      "(10, 12000)\n",
      "working on angles_20120717T103748\n",
      "(10, 12000)\n",
      "working on angles_20120717T105021\n",
      "(10, 12000)\n",
      "working on angles_20120809T100115\n",
      "(10, 12000)\n",
      "working on angles_20120829T125604\n",
      "(10, 12000)\n",
      "working on angles_20121101T095248\n",
      "(10, 12000)\n",
      "working on angles_20121122T140316\n",
      "(10, 12000)\n",
      "working on angles_20130410T105446\n",
      "(10, 12000)\n",
      "working on angles_20130606T134651\n",
      "(10, 12000)\n",
      "working on angles_20130620T121501\n",
      "(10, 12000)\n",
      "working on angles_20130806T105329\n",
      "(10, 12000)\n",
      "working on angles_20130904T115007\n",
      "(10, 12000)\n",
      "working on angles_20130910T105157\n",
      "(10, 12000)\n",
      "working on angles_20130917T114750\n",
      "(10, 12000)\n",
      "working on angles_20130924T105459\n",
      "(10, 12000)\n",
      "working on angles_20130924T115413\n",
      "(10, 12000)\n",
      "working on angles_20131105T103758\n",
      "(10, 12000)\n",
      "working on angles_20131126T104419\n",
      "(10, 12000)\n",
      "working on angles_20131127T115511\n",
      "(10, 12000)\n",
      "working on angles_20140116T125000\n",
      "(10, 12000)\n",
      "working on angles_20140205T110432\n",
      "(10, 12000)\n",
      "working on angles_20110713T114725\n",
      "(10, 12000)\n",
      "working on angles_20110929T094056\n",
      "(10, 12000)\n",
      "working on angles_20111116T124303\n",
      "(10, 12000)\n",
      "working on angles_20120118T113903\n",
      "(10, 12000)\n",
      "working on angles_20120327T114407\n",
      "(10, 12000)\n",
      "working on angles_20120508T105413\n",
      "(10, 12000)\n",
      "working on angles_20110126T125910\n",
      "(10, 12000)\n",
      "working on angles_20110609T103144\n",
      "(10, 12000)\n",
      "working on angles_20110628T105139\n",
      "(10, 12000)\n",
      "working on angles_20140410T152849\n",
      "(10, 12000)\n",
      "working on angles_20140410T153617\n",
      "(10, 12000)\n",
      "working on angles_20140320T120724\n",
      "(10, 12000)\n",
      "working on angles_20140617T103150\n",
      "(10, 12000)\n",
      "working on angles_20140325T151745\n",
      "(10, 12000)\n",
      "working on angles_20140321T102945\n",
      "(10, 12000)\n",
      "working on angles_20140506T165539\n",
      "(10, 12000)\n",
      "working on angles_20140325T090726\n",
      "(10, 12000)\n",
      "working on angles_20140320T165100\n",
      "(10, 12000)\n",
      "working on angles_20140321T164436\n",
      "(10, 12000)\n",
      "working on angles_20140319T174655\n",
      "(10, 12000)\n",
      "working on angles_20160331T100329\n",
      "(10, 12000)\n",
      "working on angles_20140324T102916\n",
      "(10, 12000)\n",
      "working on angles_20160205T083943\n",
      "(10, 12000)\n",
      "working on angles_20160224T082034\n",
      "(10, 12000)\n",
      "working on angles_20140414T094847\n",
      "(10, 12000)\n",
      "working on angles_20140331T103844\n",
      "(10, 12000)\n",
      "working on angles_20140402T132349\n",
      "(10, 12000)\n",
      "working on angles_20140523T113613\n",
      "(10, 12000)\n",
      "working on angles_20140411T092355\n",
      "(10, 12000)\n",
      "working on angles_20140410T160801\n",
      "(10, 12000)\n",
      "working on angles_20160613T124827\n",
      "(10, 12000)\n",
      "working on angles_20151008T130905\n",
      "(10, 12000)\n",
      "working on angles_20140513T164936\n",
      "(10, 12000)\n",
      "working on angles_20140408T132129\n",
      "(10, 12000)\n",
      "working on angles_20140331T141326\n",
      "(10, 12000)\n",
      "working on angles_20140407T102830\n",
      "(10, 12000)\n",
      "working on angles_20140424T122129\n",
      "(10, 12000)\n",
      "working on angles_20140505T170702\n",
      "(10, 12000)\n",
      "working on angles_20140410T132547\n",
      "(10, 12000)\n",
      "working on angles_20140407T121948\n",
      "(10, 12000)\n",
      "working on angles_20140408T134950\n",
      "(10, 12000)\n",
      "working on angles_20160804T113749\n",
      "(10, 12000)\n",
      "working on angles_20140417T172925\n",
      "(10, 12000)\n",
      "working on angles_20140502T125436\n",
      "(10, 12000)\n",
      "working on angles_20140411T100434\n",
      "(10, 12000)\n",
      "working on angles_20140501T122450\n",
      "(10, 12000)\n",
      "working on angles_20150327T091444\n",
      "(10, 12000)\n",
      "working on angles_20140414T103836\n",
      "(10, 12000)\n",
      "working on angles_20150414T142027\n",
      "(10, 12000)\n",
      "working on angles_20140428T095137\n",
      "(10, 12000)\n",
      "working on angles_20140430T102654\n",
      "(10, 12000)\n",
      "working on angles_20140415T132354\n",
      "(10, 12000)\n",
      "working on angles_20140422T143448\n",
      "(10, 12000)\n",
      "working on angles_20150528T112418\n",
      "(10, 12000)\n",
      "working on angles_20150528T132552\n",
      "(10, 12000)\n",
      "working on angles_20140429T142750\n",
      "(10, 12000)\n",
      "working on angles_20150519T153202\n",
      "(10, 12000)\n",
      "working on angles_20150520T100309\n",
      "(10, 12000)\n",
      "working on angles_20140424T165440\n",
      "(10, 12000)\n",
      "working on angles_20150625T111628\n",
      "(10, 12000)\n",
      "working on angles_20150526T162626\n",
      "(10, 12000)\n",
      "working on angles_20150615T111100\n",
      "(10, 12000)\n",
      "working on angles_20150610T075705\n",
      "(10, 12000)\n",
      "working on angles_20150616T091801\n",
      "(10, 12000)\n",
      "working on angles_20150610T092125\n",
      "(10, 12000)\n",
      "working on angles_20150529T101931\n",
      "(10, 12000)\n",
      "working on angles_20150626T070808\n",
      "(10, 12000)\n",
      "working on angles_20140508T151620\n",
      "(10, 12000)\n",
      "working on angles_20150706T084232\n",
      "(10, 12000)\n",
      "working on angles_20150526T114627\n",
      "(10, 12000)\n",
      "working on angles_20150601T103754\n",
      "(10, 12000)\n",
      "working on angles_20150624T060429\n",
      "(10, 12000)\n",
      "working on angles_20150601T080909\n",
      "(10, 12000)\n",
      "working on angles_20150612T071711\n",
      "(10, 12000)\n",
      "working on angles_20140423T150216\n",
      "(10, 12000)\n",
      "working on angles_20150608T102006\n",
      "(10, 12000)\n",
      "working on angles_20150608T123745\n",
      "(10, 12000)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "angles_list = []\n",
    "\n",
    "for i, bq_name in enumerate(metadata_df['bq_name']):\n",
    "    if i >=100:\n",
    "        break\n",
    "\n",
    "    PROJECT = \"stridecare-461809\"\n",
    "    DATASET = \"angle_csvs\"\n",
    "    TABLE = bq_name\n",
    "\n",
    "    query = f\"\"\"       \n",
    "    SELECT *\n",
    "    FROM {PROJECT}.{DATASET}.{TABLE}\n",
    "    \"\"\"\n",
    "    print(f'working on {bq_name}')\n",
    "    client = bigquery.Client()\n",
    "    query_job = client.query(query)\n",
    "    result = query_job.result()\n",
    "    df = result.to_dataframe()\n",
    "    df = df.drop(columns=['Frame', 'L_ankle_X', 'L_ankle_Y', 'R_ankle_X', 'R_ankle_Y']).T\n",
    "    df_array = np.array(df)\n",
    "    df_array = pad_sequences(df_array, maxlen = 12000, padding=\"post\", truncating='post')\n",
    "    print(df_array.shape)\n",
    "    angles_list.append(df_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59d0c2d0-e1c1-45f6-8b85-f6847dd3aa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_angles_train = angles_list[:70]\n",
    "X_angles_test = angles_list[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dbdf977a-846b-409d-8dcd-0c82b6649790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_meta = metadata_df[['age', 'Height', 'Weight', 'Gender']]\n",
    "X_meta_train = X_meta.loc[:69, :]\n",
    "X_meta_test = X_meta.loc[69:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d8f7a12-f3dd-4e70-a150-757a78c1d325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_meta_train_preproc = scaler.fit_transform(X_meta_train.drop(columns='Gender'))\n",
    "X_meta_test_prerpoc = scaler.transform(X_meta_test.drop(columns='Gender'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dfccee62-d769-443b-9f5a-87e72bca98db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, drop=\"if_binary\")\n",
    "X_meta_train_gender = ohe.fit_transform(X_meta_train[['Gender']])\n",
    "X_meta_test_gender = ohe.transform(X_meta_test[['Gender']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c25ffcec-e7d2-4f8f-ab47-1852a766eb44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_meta_train_preproc = np.concat((X_meta_train_preproc, X_meta_train_gender), axis = 1)\n",
    "X_meta_test_preproc = np.concat((X_meta_test_prerpoc, X_meta_test_gender), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "203e4631-d8f6-4247-b450-071694972486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(metadata_df['InjJoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c75f9c20-82b1-4cce-9035-0dc9056185c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y[:100])\n",
    "y_train = y[:70]\n",
    "y_test = y[70:]\n",
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "12a1d82d-8bc3-4920-b21a-c35884d1c0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_angles_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "60efb11c-25de-4326-adbc-f826defd13f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 70\n'y' sizes: 70\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 40\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 3. Fit\u001b[39;00m\n\u001b[1;32m     35\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m                            patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     37\u001b[0m                            min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     38\u001b[0m                            restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_angles_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_meta_train_preproc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_angles_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_meta_test_preproc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 4. Predict\u001b[39;00m\n\u001b[1;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(X_test, y_test)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:115\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    111\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 70\n'y' sizes: 70\n"
     ]
    }
   ],
   "source": [
    "# DONT RUN\n",
    "\n",
    "# 0. Imports\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "### We need to pad the inputs, (from the RNN lecture), \n",
    "#     from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "#     X_pad = pad_sequences(X_token, dtype='float32', padding='pre')\n",
    "\n",
    "\n",
    "# 1. RNN Architecture\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(10,12000))) #Input shape? # Or .. (1832, 4000, n_meta_features)? (does it need # of angles)\n",
    "\n",
    "model.add(layers.LSTM(units=256, activation='tanh', return_sequences=True)) #Units all okay #return_sequences=True to bring to the next layer\n",
    "model.add(layers.LSTM(units=128, activation='tanh', return_sequences=True))\n",
    "model.add(layers.LSTM(units=64, activation='tanh', return_sequences=False)) #More hidden layers?\n",
    "          \n",
    "model.add(layers.Dense(64, activation='relu')) # leos: [4000, n_features] (???)\n",
    "model.add(layers.Dense(6, activation='softmax')) #More dense layers?\n",
    "\n",
    "\n",
    "# 2. Compilation\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "              \n",
    "# 3. Fit\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=0,\n",
    "                           min_delta=0.001,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "model.fit([X_angles_train, X_meta_train_preproc], y_train, \n",
    "          epochs=50, \n",
    "          batch_size=32, \n",
    "          validation_data = ([X_angles_test, X_meta_test_preproc], y_test),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "\n",
    "# 4. Predict\n",
    "model.predict(X_test, y_test)\n",
    "          \n",
    "\n",
    "# 5. Evaluation\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf52ddc-7171-4429-bb98-1d573132cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Imports ####\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#### 1. Architecture ####\n",
    "\n",
    "## Creating the sequential & meta inputs ##\n",
    "\n",
    "    # (1.) Time-series input (coordinates)\n",
    "time_input = Input(shape=(10,12000), name='time_series_input') #Defining input layer\n",
    "\n",
    "x = layers.LSTM(256, activation='tanh', return_sequences=True)(time_input) #Stack the layers using the syntax: new_layer()(previous_layer)\n",
    "x = layers.LSTM(128, activation='tanh', return_sequences=True)(x)\n",
    "x = layers.LSTM(64, activation='tanh', return_sequences=False)(x)  # final temporal summary\n",
    "\n",
    "x = layers.Dense(64, activation='relu')(x)  # flatten & process time branch\n",
    "\n",
    "    # (2.) Metadata Input #\n",
    "        # Assume: shape=(n_meta_features,)\n",
    "meta_input = Input(shape=(4,), name='meta_input') #do we need to add number of frames, or number of runners ?\n",
    "\n",
    "y = layers.Dense(32, activation='relu')(meta_input)\n",
    "y = layers.Dense(16, activation='relu')(y)\n",
    "\n",
    "\n",
    "## Concatenating the two-inputs ##\n",
    "\n",
    "    # (3.) Concatenate Both Branches #\n",
    "combined = layers.Concatenate()([x, y])\n",
    "z = layers.Dense(64, activation='relu')(combined)\n",
    "z = layers.Dense(6, activation='softmax')(z)  # final classification layer (6 categories)\n",
    "\n",
    "\n",
    "## Instantiating the model ##\n",
    "\n",
    "model = Model(inputs=[time_input, meta_input], outputs=z)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Compiling the model ####\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3. Fit ####\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           # min_delta=0.001,(??)\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "model.fit([X_time, X_meta],\n",
    "          y_train,\n",
    "          epochs=50,\n",
    "          batch_size=32, \n",
    "          validation_split=0.2, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stop])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 4. Predict ####\n",
    "model.predict(??, ??)\n",
    "          \n",
    "\n",
    "# 5. Evaluation\n",
    "model.evaluate(??, ??)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
