{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45260217",
   "metadata": {},
   "source": [
    "# Pose Landmarks Detection with MediaPipe Tasks\n",
    "This notebook shows you how to use MediaPipe Tasks Python API to detect pose landmarks from images.\n",
    "\n",
    "## Preparation\n",
    "Let's start with installing MediaPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba990f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa49e5",
   "metadata": {},
   "source": [
    "Then download an off-the-shelf model bundle. Check out the MediaPipe documentation for more information about this model bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9dfab",
   "metadata": {},
   "source": [
    "## Visualization utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f6428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown To better demonstrate the Pose Landmarker API, we have created a set of visualization tools that will be used in this colab. These will draw the landmarks on a detect person, as well as the expected connections between those markers.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9500b9",
   "metadata": {},
   "source": [
    "## Download test image\n",
    "To demonstrate the Pose Landmarker API, you can download a sample image using the follow code. The image is from Pixabay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6164395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement google.colab (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for google.colab\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b8bd87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget -q -O image.jpg https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m cv2_imshow(img)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "!wget -q -O image.jpg https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\n",
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b124b",
   "metadata": {},
   "source": [
    "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for filename in uploaded:\n",
    "#   content = uploaded[filename]\n",
    "#   with open(filename, 'wb') as f:\n",
    "#     f.write(content)\n",
    "\n",
    "# if len(uploaded.keys()):\n",
    "#   IMAGE_FILE = next(iter(uploaded))\n",
    "#   print('Uploaded file:', IMAGE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d97bb",
   "metadata": {},
   "source": [
    "## Running inference and visualizing the results\n",
    "The final step is to run pose landmark detection on your selected image. This involves creating your PoseLandmarker object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
    "\n",
    "Check out the MediaPipe documentation to learn more about configuration options that this solution supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed850a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an PoseLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    output_segmentation_masks=True)\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(\"image.jpg\")\n",
    "\n",
    "# STEP 4: Detect pose landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b7b25",
   "metadata": {},
   "source": [
    "Visualize the pose segmentation mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f62a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
    "visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
    "cv2_imshow(visualized_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stridecare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
