## Testing how to make angles on mediapipe output
## Step 1: need to measure angles for:
# 23 - left hip
# 24 - right hip
# 25 - left knee
# 26 - right knee
# 27 - left ankle
# 28 - right ankle
# 29 - left heel
# 30 - right heel
# 31 - left foot index
# 32 - right foot index --> these are the body landmark coordinates
import math
import cv2
import mediapipe as mp
from time import time
import os
from matplotlib import pyplot as plt

#initializing mediapipe pose class
mp_pose = mp.solutions.pose

#setting up pose function XXXXXX maybe want to edit static image mode
pose = mp_pose.Pose(static_image_mode=True, #False when we'd be using videos
                    min_detection_confidence = 0.3,
                    #min_tracking_confidence
                    model_complexity = 2) #heavy model

#initializing mediapipe drawing class, for annotation
mp_drawing = mp.solutions.drawing_utils

## reading an image
sample_img = cv2.imread('raw_data/sample_runner.jpg')
#specify size of img
plt.figure(figsize = [10, 10])
#display sample image, convert BGR to RGB for display
plt.title('sample runner');
plt.axis('off');
plt.imshow(sample_img[:,:,::-1]);
plt.show();

## Perform pose detection on image
results = pose.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))

#check if any landmarks are found
if results.pose_landmarks :
    for i in range(23,33):
        print(f'{mp_pose.PoseLandmark(i).name}:\
              \n{results.pose_landmarks.landmark[mp_pose.PoseLandmark(i).value]}')



#get original mediapipe landmarks from image: return dictionary of landmarks
# visibility
#once have dictionary, can calculate angles between x, y, z
#pose detection class: heavy, full, lite



## Step 2 : be able to divide it into x, y, z axis to compare with training dataset
